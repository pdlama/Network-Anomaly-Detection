{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "anomaly_detection-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "26nxGfVdxqMS",
        "BZaurPwrxqMX",
        "P28orAWuxqMf",
        "L-LlOJC6xqMr",
        "YS2p1jL-xqMv",
        "rL4H2PgtxqM1",
        "Gc_cZdEExqNF",
        "RxsrgWGHxqNJ",
        "TcGVvoAgxqNQ",
        "yi3WFGK_xqNV",
        "14MIvbhRxqNb",
        "b1nKcRzJxqNe"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bghw5o6xqLO"
      },
      "source": [
        "# Intrusion Detection based Anomaly method using Classification algorithms \n",
        "- Decision Tree, \n",
        "\n",
        "- Random Forest Tree, \n",
        "\n",
        "- Gradient Boost Tree, \n",
        "\n",
        "- Naive Bayes \n",
        "\n",
        "- Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWF-ZYlPxqLS"
      },
      "source": [
        "### Importing Packages and configuring spark engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI4OftoGxr_g",
        "outputId": "10f263b0-02b5-467c-ac30-adda1b0746c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ropc_P3DxqLV"
      },
      "source": [
        "import pyspark.sql.functions as funcs\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Q9pHPjxqLf"
      },
      "source": [
        "spark = SparkSession.builder\\\n",
        ".master(\"local[4]\")\\\n",
        ".appName(\"ReadFromCsv\")\\\n",
        ".config(\"spark.driver.memory\",\"3g\")\\\n",
        ".config(\"spark.executor.memory\", \"4g\")\\\n",
        ".getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o32JdwtxqLl",
        "outputId": "3d8a9171-e9f8-4a96-8f11-88573fb75e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''logger = spark.sparkContext._jvm.org.apache.log4j\n",
        "logger.LogManager.getLogger(\"org\"). setLevel(logger.Level.ERROR)\n",
        "logger.LogManager.getLogger(\"akka\").setLevel(logger.Level.ERROR)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'logger = spark.sparkContext._jvm.org.apache.log4j\\nlogger.LogManager.getLogger(\"org\"). setLevel(logger.Level.ERROR)\\nlogger.LogManager.getLogger(\"akka\").setLevel(logger.Level.ERROR)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDdasgJvxqLp"
      },
      "source": [
        "# 1. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpiBq3CTxqLr"
      },
      "source": [
        "iris = spark.read \\\n",
        ".format(\"csv\")\\\n",
        ".option(\"header\", True)\\\n",
        ".option(\"sep\", \",\")\\\n",
        ".option(\"inferSchema\", \"True\")\\\n",
        ".load(\"UNSW_NB15.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RT73OxRxxqLu",
        "outputId": "970dacd3-af3f-4095-f411-597269ab2cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "iris.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- dur: double (nullable = true)\n",
            " |-- proto: string (nullable = true)\n",
            " |-- service: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- spkts: integer (nullable = true)\n",
            " |-- dpkts: integer (nullable = true)\n",
            " |-- sbytes: integer (nullable = true)\n",
            " |-- dbytes: integer (nullable = true)\n",
            " |-- rate: double (nullable = true)\n",
            " |-- sttl: integer (nullable = true)\n",
            " |-- dttl: integer (nullable = true)\n",
            " |-- sload: double (nullable = true)\n",
            " |-- dload: double (nullable = true)\n",
            " |-- sloss: integer (nullable = true)\n",
            " |-- dloss: integer (nullable = true)\n",
            " |-- sinpkt: double (nullable = true)\n",
            " |-- dinpkt: double (nullable = true)\n",
            " |-- sjit: double (nullable = true)\n",
            " |-- djit: double (nullable = true)\n",
            " |-- swin: integer (nullable = true)\n",
            " |-- stcpb: long (nullable = true)\n",
            " |-- dtcpb: long (nullable = true)\n",
            " |-- dwin: integer (nullable = true)\n",
            " |-- tcprtt: double (nullable = true)\n",
            " |-- synack: double (nullable = true)\n",
            " |-- ackdat: double (nullable = true)\n",
            " |-- smean: integer (nullable = true)\n",
            " |-- dmean: integer (nullable = true)\n",
            " |-- trans_depth: integer (nullable = true)\n",
            " |-- response_body_len: integer (nullable = true)\n",
            " |-- ct_srv_src: integer (nullable = true)\n",
            " |-- ct_state_ttl: integer (nullable = true)\n",
            " |-- ct_dst_ltm: integer (nullable = true)\n",
            " |-- ct_src_dport_ltm: integer (nullable = true)\n",
            " |-- ct_dst_sport_ltm: integer (nullable = true)\n",
            " |-- ct_dst_src_ltm: integer (nullable = true)\n",
            " |-- is_ftp_login: integer (nullable = true)\n",
            " |-- ct_ftp_cmd: integer (nullable = true)\n",
            " |-- ct_flw_http_mthd: integer (nullable = true)\n",
            " |-- ct_src_ltm: integer (nullable = true)\n",
            " |-- ct_srv_dst: integer (nullable = true)\n",
            " |-- is_sm_ips_ports: integer (nullable = true)\n",
            " |-- attack_cat: string (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwDrOaJlxqLy"
      },
      "source": [
        "# 2. Data Preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paNzlC2wFHVg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQpbcjORASGZ"
      },
      "source": [
        "#Just for UNSW_NB15 dataset\n",
        "iris=iris.drop('proto','service','state','label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIb0YP-0AsCO",
        "outputId": "4ceec56a-f2a2-4c87-fa1b-80c8237c9ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "iris.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- dur: double (nullable = true)\n",
            " |-- spkts: integer (nullable = true)\n",
            " |-- dpkts: integer (nullable = true)\n",
            " |-- sbytes: integer (nullable = true)\n",
            " |-- dbytes: integer (nullable = true)\n",
            " |-- rate: double (nullable = true)\n",
            " |-- sttl: integer (nullable = true)\n",
            " |-- dttl: integer (nullable = true)\n",
            " |-- sload: double (nullable = true)\n",
            " |-- dload: double (nullable = true)\n",
            " |-- sloss: integer (nullable = true)\n",
            " |-- dloss: integer (nullable = true)\n",
            " |-- sinpkt: double (nullable = true)\n",
            " |-- dinpkt: double (nullable = true)\n",
            " |-- sjit: double (nullable = true)\n",
            " |-- djit: double (nullable = true)\n",
            " |-- swin: integer (nullable = true)\n",
            " |-- stcpb: long (nullable = true)\n",
            " |-- dtcpb: long (nullable = true)\n",
            " |-- dwin: integer (nullable = true)\n",
            " |-- tcprtt: double (nullable = true)\n",
            " |-- synack: double (nullable = true)\n",
            " |-- ackdat: double (nullable = true)\n",
            " |-- smean: integer (nullable = true)\n",
            " |-- dmean: integer (nullable = true)\n",
            " |-- trans_depth: integer (nullable = true)\n",
            " |-- response_body_len: integer (nullable = true)\n",
            " |-- ct_srv_src: integer (nullable = true)\n",
            " |-- ct_state_ttl: integer (nullable = true)\n",
            " |-- ct_dst_ltm: integer (nullable = true)\n",
            " |-- ct_src_dport_ltm: integer (nullable = true)\n",
            " |-- ct_dst_sport_ltm: integer (nullable = true)\n",
            " |-- ct_dst_src_ltm: integer (nullable = true)\n",
            " |-- is_ftp_login: integer (nullable = true)\n",
            " |-- ct_ftp_cmd: integer (nullable = true)\n",
            " |-- ct_flw_http_mthd: integer (nullable = true)\n",
            " |-- ct_src_ltm: integer (nullable = true)\n",
            " |-- ct_srv_dst: integer (nullable = true)\n",
            " |-- is_sm_ips_ports: integer (nullable = true)\n",
            " |-- attack_cat: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS5NDFdBxqLy"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssLoMW9uxqL2"
      },
      "source": [
        "feature_cols = iris.columns[:-1]\n",
        "#feature_cols = iris.columns[:-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv-EYlOgF8uS"
      },
      "source": [
        "Pipelining and Vector assembler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WDcCGoeDxqL5"
      },
      "source": [
        "# attack_cat for UNSW_NB15 and status for NSL KDD\n",
        "label_indexer = StringIndexer(inputCol = \"attack_cat\", outputCol = \"label\")\n",
        "assembler = VectorAssembler(inputCols = feature_cols, outputCol = 'features')\n",
        "pipe = Pipeline(stages=[assembler, label_indexer])\n",
        "pipe_model = pipe.fit(iris)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aon4Nv3qxqMI"
      },
      "source": [
        "data1 = pipe_model.transform(iris)\n",
        "data = data1.select(\"features\",\"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gqmFIoUxqML"
      },
      "source": [
        "train, test = data.randomSplit([0.70, 0.30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqAuC0mLfiac",
        "outputId": "c4982adb-79e9-4f19-cc21-14a96687a95a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "train.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(features=SparseVector(40, {0: 971.0, 1: 0.0632, 2: 4.0, 3: 4.0, 4: 2304.0, 5: 2304.0, 6: 110.8226, 7: 62.0, 8: 252.0, 9: 218858.8281, 10: 218858.8281, 13: 15.266, 14: 13.1533, 15: 21.5759, 16: 18.5903, 24: 576.0, 25: 576.0, 28: 2.0, 29: 3.0, 30: 2.0, 31: 2.0, 32: 2.0, 33: 2.0, 37: 2.0, 38: 2.0}), label=2.0),\n",
              " Row(features=SparseVector(40, {0: 3470.0, 1: 0.0632, 2: 4.0, 3: 4.0, 4: 2304.0, 5: 2304.0, 6: 110.8226, 7: 62.0, 8: 252.0, 9: 218858.8281, 10: 218858.8281, 13: 15.266, 14: 13.1533, 15: 21.5759, 16: 18.5903, 24: 576.0, 25: 576.0, 28: 2.0, 29: 3.0, 30: 2.0, 31: 2.0, 32: 2.0, 33: 2.0, 37: 2.0, 38: 2.0}), label=2.0),\n",
              " Row(features=SparseVector(40, {0: 11185.0, 1: 0.0591, 2: 4.0, 3: 4.0, 4: 2304.0, 5: 2304.0, 6: 118.5336, 7: 62.0, 8: 252.0, 9: 234086.8594, 10: 234086.8594, 13: 14.6873, 14: 11.1043, 15: 20.7611, 16: 15.6947, 24: 576.0, 25: 576.0, 28: 1.0, 29: 3.0, 30: 2.0, 31: 2.0, 32: 2.0, 33: 2.0, 37: 2.0, 38: 1.0}), label=4.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWOrP_msxqMO"
      },
      "source": [
        "# 3. Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1pJKI7iKnvZ"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbYN1vIFMyS1"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXCiZruuPzik"
      },
      "source": [
        "#clf = MultilayerPerceptronClassifier(random_state=1, max_iter=300).fit(train)\n",
        "#clf.predict_proba(test)\n",
        "#clf.score(test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLzPe0m0xqMP"
      },
      "source": [
        "### 3.1 Decision Tree Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF79QSjZxqMQ"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26nxGfVdxqMS"
      },
      "source": [
        "#### 3.1.1 Training and Predicting of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZx_vTsFxqMT",
        "outputId": "caa8c0a8-a43e-48b5-c0f5-dc53980f82a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "modeldt = dt.fit(train)\n",
        "predictiondt = modeldt.transform(test)\n",
        "predictiondt.toPandas().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>label</th>\n",
              "      <th>rawPrediction</th>\n",
              "      <th>probability</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(5990.0, 0.127695, 4.0, 4.0, 1954.0, 2170.0, 5...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[17.0, 27.0, 904.0, 201.0, 1023.0, 120.0, 81.0...</td>\n",
              "      <td>[0.007013201320132013, 0.011138613861386138, 0...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(8454.0, 1.375599, 4.0, 4.0, 1676.0, 2776.0, 5...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[17.0, 27.0, 904.0, 201.0, 1023.0, 120.0, 81.0...</td>\n",
              "      <td>[0.007013201320132013, 0.011138613861386138, 0...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(8786.0, 17.625374, 250.0, 24.0, 248562.0, 165...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[17.0, 27.0, 904.0, 201.0, 1023.0, 120.0, 81.0...</td>\n",
              "      <td>[0.007013201320132013, 0.011138613861386138, 0...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(8788.0, 17.625374, 250.0, 24.0, 248562.0, 165...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[17.0, 27.0, 904.0, 201.0, 1023.0, 120.0, 81.0...</td>\n",
              "      <td>[0.007013201320132013, 0.011138613861386138, 0...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(8998.0, 17.625374, 250.0, 24.0, 248562.0, 165...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[17.0, 27.0, 904.0, 201.0, 1023.0, 120.0, 81.0...</td>\n",
              "      <td>[0.007013201320132013, 0.011138613861386138, 0...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            features  ...  prediction\n",
              "0  (5990.0, 0.127695, 4.0, 4.0, 1954.0, 2170.0, 5...  ...         4.0\n",
              "1  (8454.0, 1.375599, 4.0, 4.0, 1676.0, 2776.0, 5...  ...         4.0\n",
              "2  (8786.0, 17.625374, 250.0, 24.0, 248562.0, 165...  ...         4.0\n",
              "3  (8788.0, 17.625374, 250.0, 24.0, 248562.0, 165...  ...         4.0\n",
              "4  (8998.0, 17.625374, 250.0, 24.0, 248562.0, 165...  ...         4.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZaurPwrxqMX"
      },
      "source": [
        "#### 3.1.2 Confusion Matrix of Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aStqYedoxqMY",
        "outputId": "d906003a-c6ec-4374-ef3c-9bf9ead8f930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "predictiondt.select(\"prediction\", \"label\")\\\n",
        ".groupBy(\"prediction\", \"label\").count()\\\n",
        ".orderBy(\"prediction\", \"label\", ascending=True).withColumn(\"attack_cat\",\n",
        "funcs.when(funcs.col(\"label\").isin(1), \"Anomaly\")\\\n",
        ".otherwise(\"Normal\")).toPandas().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "      <th>label</th>\n",
              "      <th>count</th>\n",
              "      <th>attack_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10731</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Anomaly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5165</td>\n",
              "      <td>Anomaly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   prediction  label  count attack_cat\n",
              "0         0.0    0.0  10731     Normal\n",
              "1         0.0    1.0      4    Anomaly\n",
              "2         0.0    2.0      6     Normal\n",
              "3         1.0    1.0   5165    Anomaly\n",
              "4         1.0    2.0      1     Normal"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SQk8R0c-xqMb",
        "outputId": "e0d19939-cb09-4235-b0be-82e9261ea9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "predictiondt.groupBy([\"label\",\"prediction\"]).count().toPandas().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  prediction  count\n",
              "0    8.0         3.0     71\n",
              "1    2.0         0.0      6\n",
              "2    7.0         3.0     61\n",
              "3    3.0         5.0     10\n",
              "4    9.0         5.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28orAWuxqMf"
      },
      "source": [
        "#### 3.1.3 Calculation of Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "q63kHQa5xqMg",
        "outputId": "9aea255a-1d0d-459a-ff22-4b23afcfa111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "evaluatordt = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "dt = evaluatordt.evaluate(predictiondt)\n",
        "\n",
        "print(\"--- Decision Tree --- \")\n",
        "print(\"Accuracy Rate =\", round(dt,4))\n",
        "print(\"  Error  Rate = %g \" % round((1.0 - dt),4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Decision Tree --- \n",
            "Accuracy Rate = 0.8291\n",
            "  Error  Rate = 0.1709 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXGuV6-RxqMj",
        "outputId": "d18b4962-3280-44d0-8e19-7708d121581a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "predictionAndLabel = predictiondt.select(\"prediction\", \"label\").rdd\n",
        "\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "metrics = MulticlassMetrics(predictionAndLabel)\n",
        "cm = metrics.confusionMatrix()\n",
        "rows = cm.toArray().tolist()\n",
        "\n",
        "confusion_matrix = spark.createDataFrame(rows,[\"normal\",\"anomaly\"])\n",
        "confusion_matrix.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+------+-----+-----+---+---+---+---+\n",
            "| normal|anomaly|    _3|    _4|   _5|   _6| _7| _8| _9|_10|\n",
            "+-------+-------+------+------+-----+-----+---+---+---+---+\n",
            "|10731.0|    0.0|  47.0| 233.0| 10.0|  2.0|0.0|0.0|0.0|0.0|\n",
            "|    4.0| 5165.0|  81.0| 352.0|  9.0|  0.0|0.0|0.0|0.0|0.0|\n",
            "|    6.0|    1.0|2107.0| 533.0|615.0|107.0|0.0|0.0|0.0|0.0|\n",
            "|    0.0|    0.0| 273.0|1420.0|108.0| 10.0|0.0|0.0|0.0|0.0|\n",
            "|    0.0|    1.0| 340.0| 170.0|655.0| 55.0|0.0|0.0|0.0|0.0|\n",
            "|    0.0|    0.0|  23.0| 593.0| 95.0|375.0|0.0|0.0|0.0|0.0|\n",
            "|    0.0|    0.0| 129.0|  47.0| 43.0|  0.0|0.0|0.0|0.0|0.0|\n",
            "|    0.0|    0.0| 118.0|  61.0| 17.0|  3.0|0.0|0.0|0.0|0.0|\n",
            "|    0.0|    0.0|   4.0|  71.0| 13.0| 29.0|0.0|0.0|0.0|0.0|\n",
            "|    0.0|    0.0|   3.0|   9.0|  0.0|  1.0|0.0|0.0|0.0|0.0|\n",
            "+-------+-------+------+------+-----+-----+---+---+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEegDWIBxqMm",
        "outputId": "70084986-3360-4394-e8cb-6364ec60c121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "predictiondt.withColumn(\"A\", funcs.struct(\"prediction\",\"label\")).crosstab(\"prediction\",\"label\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-----+----+----+----+---+---+---+---+---+---+\n",
            "|prediction_label|  0.0| 1.0| 2.0| 3.0|4.0|5.0|6.0|7.0|8.0|9.0|\n",
            "+----------------+-----+----+----+----+---+---+---+---+---+---+\n",
            "|             0.0|10731|   4|   6|   0|  0|  0|  0|  0|  0|  0|\n",
            "|             5.0|    2|   0| 107|  10| 55|375|  0|  3| 29|  1|\n",
            "|             1.0|    0|5165|   1|   0|  1|  0|  0|  0|  0|  0|\n",
            "|             2.0|   47|  81|2107| 273|340| 23|129|118|  4|  3|\n",
            "|             3.0|  233| 352| 533|1420|170|593| 47| 61| 71|  9|\n",
            "|             4.0|   10|   9| 615| 108|655| 95| 43| 17| 13|  0|\n",
            "+----------------+-----+----+----+----+---+---+---+---+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1fs_l73xqMo"
      },
      "source": [
        "### 3.2 Random Forest Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEcwOIK0xqMp"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-LlOJC6xqMr"
      },
      "source": [
        "#### 3.2.1 Training and Predicting of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ZLhKHfE9xqMs",
        "outputId": "20c5969c-5ccb-42cd-a554-29c618b5c904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
        "modelrf = rf.fit(train)\n",
        "predictionrf = modelrf.transform(test)\n",
        "predictionrf.toPandas().head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>label</th>\n",
              "      <th>rawPrediction</th>\n",
              "      <th>probability</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(5990.0, 0.127695, 4.0, 4.0, 1954.0, 2170.0, 5...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[2.126080365437323, 0.3498441422312224, 4.4660...</td>\n",
              "      <td>[0.21260803654373225, 0.034984414223122234, 0....</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(8454.0, 1.375599, 4.0, 4.0, 1676.0, 2776.0, 5...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[2.220944670743943, 0.3889904825653168, 4.7273...</td>\n",
              "      <td>[0.2220944670743943, 0.03889904825653168, 0.47...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(8786.0, 17.625374, 250.0, 24.0, 248562.0, 165...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[1.5329423830961466, 0.3972663621003929, 4.980...</td>\n",
              "      <td>[0.15329423830961467, 0.03972663621003929, 0.4...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            features  ...  prediction\n",
              "0  (5990.0, 0.127695, 4.0, 4.0, 1954.0, 2170.0, 5...  ...         2.0\n",
              "1  (8454.0, 1.375599, 4.0, 4.0, 1676.0, 2776.0, 5...  ...         2.0\n",
              "2  (8786.0, 17.625374, 250.0, 24.0, 248562.0, 165...  ...         2.0\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS2p1jL-xqMv"
      },
      "source": [
        "#### 3.2.2 Calculation of Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB9W1-CqxqMw",
        "outputId": "93443a9a-44cd-40f2-8c2e-fc419f8fa8ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "evaluatorrf = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "rf = evaluatorrf.evaluate(predictionrf)\n",
        "\n",
        "print(\"--- Random Forest Tree --- \")\n",
        "print(\"Accuracy Rate =\", round(rf,4))\n",
        "print(\"  Error  Rate = %g \" % round((1.0 - rf),4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Random Forest Tree --- \n",
            "Accuracy Rate = 0.8052\n",
            "  Error  Rate = 0.1948 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL4H2PgtxqM1"
      },
      "source": [
        "#### 3.2.3 Confusion Matrix of Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "dGhort1wxqM2",
        "outputId": "ccc9c9ee-781e-4bdf-e0de-481c4e51857c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "predictionAndLabel = predictionrf.select(\"prediction\", \"label\").rdd\n",
        "\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "metrics = MulticlassMetrics(predictionAndLabel)\n",
        "cm = metrics.confusionMatrix()\n",
        "rows = cm.toArray().tolist()\n",
        "\n",
        "confusion_matrix = spark.createDataFrame(rows,[\"normal\",\"anomaly\"])\n",
        "confusion_matrix.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+-----+---+-----+---+---+---+---+\n",
            "| normal|anomaly|    _3|   _4| _5|   _6| _7| _8| _9|_10|\n",
            "+-------+-------+------+-----+---+-----+---+---+---+---+\n",
            "|10905.0|    0.0| 110.0|  7.0|0.0|  1.0|0.0|0.0|0.0|0.0|\n",
            "|   56.0| 5392.0| 142.0| 16.0|0.0|  5.0|0.0|0.0|0.0|0.0|\n",
            "|  372.0|    3.0|2956.0| 24.0|0.0| 14.0|0.0|0.0|0.0|0.0|\n",
            "| 1168.0|    0.0| 433.0|209.0|0.0|  1.0|0.0|0.0|0.0|0.0|\n",
            "|   98.0|   10.0|1091.0|  5.0|3.0| 14.0|0.0|0.0|0.0|0.0|\n",
            "|  202.0|    0.0| 482.0|  3.0|0.0|399.0|0.0|0.0|0.0|0.0|\n",
            "|   20.0|    0.0| 199.0|  0.0|0.0|  0.0|0.0|0.0|0.0|0.0|\n",
            "|   17.0|    4.0| 177.0|  0.0|0.0|  1.0|0.0|0.0|0.0|0.0|\n",
            "|   28.0|    0.0|  67.0| 13.0|0.0|  9.0|0.0|0.0|0.0|0.0|\n",
            "|    2.0|    0.0|  11.0|  0.0|0.0|  0.0|0.0|0.0|0.0|0.0|\n",
            "+-------+-------+------+-----+---+-----+---+---+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64UDdUBYxqM4",
        "outputId": "e1622086-571d-46f6-9acf-96f3d5d9ba2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "predictionAndLabels = predictionrf.select(\"prediction\", \"label\").rdd\n",
        "metrics = MulticlassMetrics(predictionAndLabels)\n",
        "metrics.confusionMatrix()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseMatrix(10, 10, [10905.0, 56.0, 372.0, 1168.0, 98.0, 202.0, 20.0, 17.0, ..., 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqngljUxqM7",
        "outputId": "fd00b1ed-3b60-4342-ffdf-449e13c283dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "predictionrf.withColumn(\"A\", funcs.struct(\"prediction\",\"label\")).crosstab(\"prediction\",\"label\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-----+----+----+----+----+---+---+---+---+---+\n",
            "|prediction_label|  0.0| 1.0| 2.0| 3.0| 4.0|5.0|6.0|7.0|8.0|9.0|\n",
            "+----------------+-----+----+----+----+----+---+---+---+---+---+\n",
            "|             0.0|10905|  56| 372|1168|  98|202| 20| 17| 28|  2|\n",
            "|             5.0|    1|   5|  14|   1|  14|399|  0|  1|  9|  0|\n",
            "|             1.0|    0|5392|   3|   0|  10|  0|  0|  4|  0|  0|\n",
            "|             2.0|  110| 142|2956| 433|1091|482|199|177| 67| 11|\n",
            "|             3.0|    7|  16|  24| 209|   5|  3|  0|  0| 13|  0|\n",
            "|             4.0|    0|   0|   0|   0|   3|  0|  0|  0|  0|  0|\n",
            "+----------------+-----+----+----+----+----+---+---+---+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9ECyN0O3xqM-",
        "outputId": "5cb4ab9f-f6cf-496a-f54e-b00b93bfe746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "predictionrfevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
        "                    labelCol=\"label\",metricName=\"accuracy\")\n",
        "predictionrfevaluator.evaluate(predictionrf)      \n",
        "\n",
        "predictionrf.groupBy(\"label\",\"prediction\").count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  8.0|       3.0|   13|\n",
            "|  2.0|       0.0|  372|\n",
            "|  3.0|       5.0|    1|\n",
            "|  8.0|       5.0|    9|\n",
            "|  0.0|       5.0|    1|\n",
            "|  5.0|       2.0|  482|\n",
            "|  8.0|       0.0|   28|\n",
            "|  1.0|       1.0| 5392|\n",
            "|  9.0|       0.0|    2|\n",
            "|  7.0|       1.0|    4|\n",
            "|  3.0|       2.0|  433|\n",
            "|  4.0|       5.0|   14|\n",
            "|  4.0|       2.0| 1091|\n",
            "|  9.0|       2.0|   11|\n",
            "|  7.0|       2.0|  177|\n",
            "|  2.0|       2.0| 2956|\n",
            "|  1.0|       0.0|   56|\n",
            "|  5.0|       3.0|    3|\n",
            "|  6.0|       2.0|  199|\n",
            "|  2.0|       3.0|   24|\n",
            "+-----+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-bRm7BDxqNC"
      },
      "source": [
        "### 3.3 Naive Bayes Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHokyqFaxqNC"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc_cZdEExqNF"
      },
      "source": [
        "#### 3.3.1 Training and Predicting of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnb3zO9axqNF",
        "outputId": "cb8716ee-2eaf-4c95-a8d0-b2a0795ddeed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
        "\n",
        "modelnb = nb.fit(train)\n",
        "predictionnb = modelnb.transform(test)\n",
        "predictionnb.toPandas().head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>label</th>\n",
              "      <th>rawPrediction</th>\n",
              "      <th>probability</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(5990.0, 0.127695, 4.0, 4.0, 1954.0, 2170.0, 5...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[-1328365.6312262518, -1272030.02668413, -1606...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(8454.0, 1.375599, 4.0, 4.0, 1676.0, 2776.0, 5...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[-313832.464825093, -301525.3775745601, -35010...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(8786.0, 17.625374, 250.0, 24.0, 248562.0, 165...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[-4013470.1830401034, -3401162.323599091, -347...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            features  ...  prediction\n",
              "0  (5990.0, 0.127695, 4.0, 4.0, 1954.0, 2170.0, 5...  ...         1.0\n",
              "1  (8454.0, 1.375599, 4.0, 4.0, 1676.0, 2776.0, 5...  ...         1.0\n",
              "2  (8786.0, 17.625374, 250.0, 24.0, 248562.0, 165...  ...         4.0\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxsrgWGHxqNJ"
      },
      "source": [
        "#### 3.3.2 Calculation of Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF-1YOUgxqNJ",
        "outputId": "0e24cc7e-00e1-4fbd-abd9-659163eb70e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "evaluatornb = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
        "                                              predictionCol=\"prediction\", \n",
        "                                              metricName=\"accuracy\")\n",
        "nb = evaluatornb.evaluate(predictionnb)\n",
        "\n",
        "print(\"--- Naive Bayes --- \")\n",
        "print(\"Accuracy Rate =\", round(nb,4))\n",
        "print(\"  Error  Rate = %g \" % round((1.0 - nb),4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Naive Bayes --- \n",
            "Accuracy Rate = 0.4712\n",
            "  Error  Rate = 0.5288 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOtQv9IqxqNM"
      },
      "source": [
        "### 3.4 Gradient Boost Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOVRBkMcxqNM"
      },
      "source": [
        "from pyspark.ml.classification import GBTClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcGVvoAgxqNQ"
      },
      "source": [
        "#### 3.4.1 Training and Predicting of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Rf5BoieIxqNR",
        "outputId": "9b0c7797-9d76-4a0c-b625-a0902dcaf7db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
        "\n",
        "#modelgbt = gbt.fit(train)\n",
        "#predictiongbt = modelgbt.transform(test)\n",
        "#predictiongbt.toPandas().head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-161-395737377255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodelgbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictiongbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelgbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictiongbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3132.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 588.0 failed 1 times, most recent failure: Lost task 0.0 in stage 588.0 (TID 6398, 70131ebac05d, executor driver): java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:177)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:174)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:95)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$SliceIterator.next(Iterator.scala:271)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1423)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1423)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1396)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:119)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.boost(GradientBoostedTrees.scala:333)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.run(GradientBoostedTrees.scala:61)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$1(GBTClassifier.scala:210)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:171)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:59)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:150)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:177)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:174)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:95)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$SliceIterator.next(Iterator.scala:271)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1423)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi3WFGK_xqNV"
      },
      "source": [
        "#### 3.4.2 Calculation of Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XRnrkq_axqNW"
      },
      "source": [
        "#evaluatorgbt = MulticlassClassificationEvaluator(\n",
        "  #  labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "#gbt = evaluatorgbt.evaluate(predictiongbt)\n",
        "\n",
        "print(\"--- Gradient Boost Tree --- \")\n",
        "print(\"Accuracy Rate =\", round(gbt,4))\n",
        "print(\"  Error  Rate = %g \" % round((1.0 - gbt),4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyPwDW5xxqNY"
      },
      "source": [
        "### 3.5 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cPfpqFnxqNZ"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14MIvbhRxqNb"
      },
      "source": [
        "#### 3.5.1 Training and Predicting of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fcE-0kQhxqNc"
      },
      "source": [
        "lr = LogisticRegression(regParam=0.01)\n",
        "modellr = lr.fit(train)\n",
        "predictionlr = modellr.transform(test)\n",
        "predictionlr.toPandas().head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1nKcRzJxqNe"
      },
      "source": [
        "#### 3.5.2 Calculation of Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwmanSe3xqNf"
      },
      "source": [
        "evaluatorlr = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "lr = evaluatorlr.evaluate(predictionlr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEetsM9lxqNi",
        "outputId": "a7b670a8-631e-4e1c-95ed-4772be5795e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"--- Logistic Regression --- \")\n",
        "print(\"Accuracy Rate =\", round(lr,4))\n",
        "print(\"  Error  Rate = %g \" % round((1.0 - lr),4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Logistic Regression --- \n",
            "Accuracy Rate = 0.7602\n",
            "  Error  Rate = 0.2398 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iFfPkIZxqNm"
      },
      "source": [
        "## 3.6 Comparison of Accucary  Rate of Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c96wPlYIxqNm",
        "outputId": "4b455b64-d9f9-46ab-be5f-edd990e8f267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#print(\"Gradient Boost Tree Accuracy =\", round(gbt,5))\n",
        "print(\"      Decision Tree Accuracy =\", round(dt,5))\n",
        "print(\" Random Forest Tree Accuracy =\", round(rf,5))\n",
        "print(\"Logistic Regression Accuracy =\", round(lr,5))\n",
        "print(\"        Naive Bayes Accuracy =\", round(nb,5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Decision Tree Accuracy = 0.8291\n",
            " Random Forest Tree Accuracy = 0.80522\n",
            "Logistic Regression Accuracy = 0.76018\n",
            "        Naive Bayes Accuracy = 0.4712\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}